---
title: "Enonce TD"
output: html_document
---


# Premier pas en apprentissage machine

## Préparartion du jeu de données titanic

```{r}
library(tidyverse)
#lire la base de données titanic

#Selectionner les variables d'interêt

#Transformer la variable cabin en binaire

# Remplacer les valeurs manquantes de l'âge par la moyenne

#Transformer les variables en qualitatives
```

## Séparation en jeu de données d'entrainement et de de validation

- utilisation de la fonction sample

```{r}
#aide de la fonction sample
?sample
# Définition de la "graine" d'aléatoire
set.seed(12)

```



## Utilisation de la régression logistique 


```{r}
library(caret)
# Define training control
set.seed(123) 
train.control <- trainControl(method = "cv", number = 10)
# Train the model
model <- train(survived ~., data = BDD_entrainement, method = "glm",
               trControl = train.control)
# Summarize the results
print(model)
```

### CV à la main

```{r}
#Mélanger les données
BDD_entrainement<-BDD_entrainement[sample(nrow(BDD_entrainement)),]

#Séparation en 10 jeu de données
folds <- cut(seq(1,nrow(BDD_entrainement)),breaks=10,labels=FALSE)
```

### Entrainement d'une glm

- entraineement sur 90% des données 

```{r}
#Entrainer un glm sur le premier fold
fit<- glm(...)
summary(fit)
```

- prédictions du modèles sur ces données

```{r}
predictions<- predict(...)
```

- graphique des ces prédictions 


```{r}
hist(predictions)
```

- tableau de contigence pour un seuil à 0.5

```{r}
table(...)
```

- courbe roc

```{r}
library(pROC)
roc<-roc( BDD_entrainement$survived[!folds==1],predictions )
(roc)
plot(roc)

coords(roc,seq(0,1,0.05))


```
Meilleur seuil

```{r}
coords(roc, "best")
```

```{r}
# Fonction pour les caractéristique d'un test
caract_test<-function(pred, verite){
  
  VN =...
  VP = ...
  FN = ...
  FP= ...
  return(
    c(specificite =... ,
      sensibilite =...,
      VPP = ...,
      VPN = ...)
  )
}

caract_test(predictions>0.5, BDD_entrainement$survived[!folds==1]==1 )

caract_test(predictions>..., BDD_entrainement$survived[!folds==1] ==1)
```




- cross validation 

```{r}
# Seuils de la courbe roc
sequence_seuil<- seq(0,1,0.05)


res_data <- data.frame()
for (i in 1:10) {
  ...
  
  
  res_data <- rbind(res_data,
                    data.frame(
                      it = i,
                      coords(
                        roc_i,
                        sequence_seuil,
                        ret = c(
                          "threshold",
                          "specificity",
                          "sensitivity",
                          "accuracy",
                          "youden"
                        )
                      )
                      ,
                      best = coords(roc_i, "best")
                    ))
}

ggplot(res_data, aes(x = threshold, y =specificity, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =sensitivity, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =accuracy, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =youden, group = threshold))+geom_boxplot()

```


## Arbre de décision

```{r}
library(rpart)

model <- rpart(...)
par(xpd = NA)
plot(model)
text(model)
```


```{r}
set.seed(123)
model2 <- train(
 ..., data = BDD_entrainement, method = "rpart",
  trControl = trainControl("cv", number = 10)
  )
# Plot model accuracy vs different values of
# cp (complexity parameter)
plot(model2)
```


```{r}
model2$bestTune
```

```{r}
par(xpd = NA) 
plot(model2$finalModel)
text(model2$finalModel,  digits = 3)
```

## random forest

```{r}
library(ranger)
rf_grid <- expand.grid(mtry = c(1,1.5,2),
                       splitrule = "gini",
                      
                      min.node.size = c( 3, 5,6))
rf_grid
fit_control <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
```

```{r}
rf_fit <- train(survived ~ ., 
                data = BDD_entrainement, 
                method = "ranger",
                trControl = fit_control,
              importance = 'impurity',
                # provide a grid of parameters
                tuneGrid = rf_grid)
rf_fit
```

```{r}
rf_fit$finalModel
```


```{r}
varImp(rf_fit)
```

# Comparaison des algos 

### Regression
```{r}
fit<- glm(survived ~ . , data = BDD_entrainement, family = "binomial")
predicted_classes_glm <- predict(fit,BDD_validation, "response")
# Compute model accuracy rate on test data
mean((predicted_classes_glm>0.3) == (BDD_validation$survived==1))
```


### Arbre de décision 

```{r}
predicted.classes <- model2 %>% predict(BDD_validation)
# Compute model accuracy rate on test data
mean(predicted.classes == BDD_validation$survived)
```


### random forest

```{r}

predicted_classes_rf <- predict(rf_fit,BDD_validation, "raw")
# Compute model accuracy rate on test data
mean( predicted_classes_rf== BDD_validation$survived)


```


