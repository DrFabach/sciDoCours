---
title: "Enonce TD"
output: html_document
---


# Premier pas en apprentissage machine

## Préparartion du jeu de données titanic

```{r}
library(tidyverse)
#lire la base de données titanic
BDD<- read.csv("Titanic_R.csv", na.strings = c(" ",""))
str(BDD)
#Selectionner les variables d'interêt
BDD<- BDD %>% select(survived,
                     age,
                     sibsp,
                     parch,
                     cabin,
                     Gender,
                     pclass =ï..pclass)

str(BDD)
#Transformer la variable cabin en binaire
BDD$cabin<- ifelse(is.na(BDD$cabin),
                   "no cabin",
                   "cabin")
# Remplacer les valeurs manquantes de l'âge par la moyenne
BDD$age<- ifelse(is.na(BDD$age),
                 mean(BDD$age, na.rm = T),
                 BDD$age)
#Transformer les variables en qualitatives
summary(BDD)
BDD$Gender<- as.factor(BDD$Gender)
BDD$survived<- as.factor(BDD$survived)
BDD$cabin<- as.factor(BDD$cabin)
# BDD$pclass<- as.factor(BDD$pclass)
summary(BDD)
```

## Séparation en jeu de données d'entrainement et de de validation

- utilisation de la fonction sample

```{r}
#aide de la fonction sample
?sample
# Définition de la "graine" d'aléatoire
set.seed(12)
nb_individu<-dim(BDD)[1]
id<- 1:nb_individu

id_validation<- sample(id, 0.2*nb_individu)

BDD_validation <- BDD[id_validation,]
BDD_entrainement<- BDD[-id_validation,]
```



## Utilisation de la régression logistique 

```{r}
fit<- glm(survived~age + sibsp +parch+cabin+Gender+factor(pclass), BDD, family = "binomial")
summary(fit)
```


```{r}
library(caret)
library(e1071)
# Define training control
BDD$pclass<- as.factor(BDD$pclass)
set.seed(123) 

train.control <- trainControl(method = "cv", number = 10)
# Train the model
model <- train(survived ~., data = BDD_entrainement, method = "glm",
               trControl = train.control)
# Summarize the results
print(model)

table(predict(model,BDD_entrainement ),
      BDD_entrainement$survived)
```

### CV à la main

```{r}
#Mélanger les données
set.seed(12)
BDD_entrainement<-BDD_entrainement[sample(nrow(BDD_entrainement)),]

#Séparation en 10 jeu de données
folds <- cut(seq(1,nrow(BDD_entrainement)),breaks=10,labels=FALSE)
```

### Entrainement d'une glm

- entraineement sur 90% des données 

```{r}
#Entrainer un glm sur le premier fold
fit<- glm(...)
summary(fit)
```

- prédictions du modèles sur ces données

```{r}
predictions<- predict(...)
```

- graphique des ces prédictions 


```{r}
hist(predictions)
```

- tableau de contigence pour un seuil à 0.5

```{r}
table(...)
```

- courbe roc

```{r}
library(pROC)
roc<-roc( BDD_entrainement$survived[!folds==1],predictions )
(roc)
plot(roc)

coords(roc,seq(0,1,0.05))


```
Meilleur seuil

```{r}
coords(roc, "best")
```

```{r}
# Fonction pour les caractéristique d'un test
caract_test<-function(pred, verite){
  
  VN =...
  VP = ...
  FN = ...
  FP= ...
  return(
    c(specificite =... ,
      sensibilite =...,
      VPP = ...,
      VPN = ...)
  )
}

caract_test(predictions>0.5, BDD_entrainement$survived[!folds==1]==1 )

caract_test(predictions>..., BDD_entrainement$survived[!folds==1] ==1)
```




- cross validation 

```{r}
# Seuils de la courbe roc
sequence_seuil<- seq(0,1,0.05)


res_data <- data.frame()
for (i in 1:10) {
  ...
  
  
  res_data <- rbind(res_data,
                    data.frame(
                      it = i,
                      coords(
                        roc_i,
                        sequence_seuil,
                        ret = c(
                          "threshold",
                          "specificity",
                          "sensitivity",
                          "accuracy",
                          "youden"
                        )
                      )
                      ,
                      best = coords(roc_i, "best")
                    ))
}

ggplot(res_data, aes(x = threshold, y =specificity, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =sensitivity, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =accuracy, group = threshold))+geom_boxplot()
ggplot(res_data, aes(x = threshold, y =youden, group = threshold))+geom_boxplot()

```


## Arbre de décision

```{r}
library(rpart)

model <- rpart(...)
par(xpd = NA)
plot(model)
text(model)
```


```{r}
set.seed(123)
model2 <- train(
 ..., data = BDD_entrainement, method = "rpart",
  trControl = trainControl("cv", number = 10)
  )
# Plot model accuracy vs different values of
# cp (complexity parameter)
plot(model2)
```


```{r}
model2$bestTune
```

```{r}
par(xpd = NA) 
plot(model2$finalModel)
text(model2$finalModel,  digits = 3)
```

## random forest

```{r}
library(ranger)
rf_grid <- expand.grid(mtry = c(1,1.5,2),
                       splitrule = "gini",
                      
                      min.node.size = c( 3, 5,6))
rf_grid
fit_control <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
```

```{r}
rf_fit <- train(survived ~ ., 
                data = BDD_entrainement, 
                method = "ranger",
                trControl = fit_control,
              importance = 'impurity',
                # provide a grid of parameters
                tuneGrid = rf_grid)
rf_fit
```

```{r}
rf_fit$finalModel
```


```{r}
varImp(rf_fit)
```

# Comparaison des algos 

### Regression
```{r}
fit<- glm(survived ~ . , data = BDD_entrainement, family = "binomial")
predicted_classes_glm <- predict(fit,BDD_validation, "response")
# Compute model accuracy rate on test data
mean((predicted_classes_glm>0.3) == (BDD_validation$survived==1))
```


### Arbre de décision 

```{r}
predicted.classes <- model2 %>% predict(BDD_validation)
# Compute model accuracy rate on test data
mean(predicted.classes == BDD_validation$survived)
```


### random forest

```{r}

predicted_classes_rf <- predict(rf_fit,BDD_validation, "raw")
# Compute model accuracy rate on test data
mean( predicted_classes_rf== BDD_validation$survived)


```


